---
title: "Assignment-7"
author: "Jason Hurst"
output: github_document
  word_document: default
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r libraries}
library(tidyverse)
library(knitr)
library(modelr)
library(caret)
library(forcats)
```

## 1. Calculate the proportion of lemons in the training dataset using the IsBadBuy variable.

Download the lemons dataset, which is a subset of the dataset used for a Kaggle competition described here: https://www.kaggle.com/c/DontGetKicked/data.

## Dependent Variable
 
 Our dependent variable is a binary variable, `IsBadBuy` that denotes whether the vehicle was a lemon. 
 
```{r}
table(training$IsBadBuy)
```


This tells us the raw numbers. Lots of times we want to know the proportions. The function `prop.table` can do this for us. 

```{r}
prop.table(table(training$IsBadBuy))
```
## Conditional Means as a Classifier

We'll start by generating some cross tabs and some quick plots, showing the probability of receiving pizza according to several characteristics of the post.  We start with a basic crosstab of the dependent variable. We use `prop.table` to change this from raw counts to proportions. I also provide a brief exampl of how to do a table using the `kable` function. 

```{r descriptives}
#Cross Tabs
# training <- read.csv("~/Dropbox/Vandy/Classes/8200/Resources/week8_resources_2_2_2_2/training.csv", header=FALSE)
save(training,file="lemon.Rdata")

training%>%
  count(IsBadBuy)%>% # Count numbers that are lemons
  mutate(p=prop.table(n))%>% #mutate for proportions using prop.table
  kable(format="markdown") # output to table

```
So, about 87.7% of the sample were not lemons, about 12.3% were lemons.


## 2. Calculate the proportion of lemons by Make.

Next, we cross-tabulate lemons with by make. 
```{r condtional_means}
#Predictions using conditional means

training%>%group_by(Make)%>%summarize(mean(IsBadBuy))

```

```{r}
prop.table(table(training$Make,training$IsBadBuy),margin=1)
```

```{r}
g_table<-table(training$Make,training$IsBadBuy);g_table

prop.table(g_table,margin=1)
```

Note how the mean of IsBadBuy is equivalent to the proportion answering "1" in the following table. 

```{r}
lem_sum<-training%>%
  group_by(Make,VehicleAge,VehOdo)%>%
  summarize(mean_lemon=mean(IsBadBuy))%>%
  arrange(-mean_lemon)

lem_sum%>%kable()

```

## 3. Now, predict the probability of being a lemon using a linear model (lm(y~x), with covariates of your choosing from the training dataset.

## Classification Using Linear Probability Model

We can use standard OLS regression for classification. It's not ideal, but most of the time it's actually not too bad, either. Below we model the binary outcome of buying a lemon as a function of Vehicle Age, Odometer, Cost of the Warranty, and make of vehicle.

```{r linear_model}
# Linear model
lem_mod<-lm(IsBadBuy~
             VehicleAge+
             VehOdo+
             WarrantyCost+
             Make,
           data=training,y=TRUE,na.exclude=TRUE);summary(lem_mod)
```

## 4. Make predictions from the linear model.

```{r}
#Predictions
training<-training%>%
  add_predictions(lem_mod)%>% ## Add in predictions from the model
  rename(pred_lem=pred)%>% ## rename to be predictions from ols (lm)
  mutate(pred_lem_out=ifelse(pred_lem>=.5,1,0))
```

Let's create a table that shows the predictions of our model against what actually happened
```{r}
predlem_table<-table(training$IsBadBuy,training$pred_lem_out)

predlem_table

prop.table(predlem_table)
rownames(predlem_table)<-c("Predicted 0","Predicted 1")
colnames(predlem_table)<-c("Actually 0","Actually 1")
```

```{r}
ModelMetrics::confusionMatrix(training$IsBadBuy,training$pred_lem_out)
caret::confusionMatrix(as.factor(training$IsBadBuy),as.factor(training$pred_lem_out))
```

## 5. Now, predict the probability of being a lemon using a logistic regression (glm(y~x,family=binomial(link="logit"))), again using covariates of your choosing.


## Logistic regression as a classifier

Logistic regression is set up to handle binary outcomes as the dependent variable. In particular, the predictions will always be a probability, which makes it better than the ironically named linear probability model. The downside to logistic regression is that it is modeling the log odds of the outcome, which means all of the coefficients are expressed as log odds, which no one understands intuitively. In this class, we're going to concentrate on logistic regression's ability to produce probabilities as predictions. Below I run the same model using logistic regression. Note the use of `glm` and the `family` option, which specifies a functional form and a particular link function. 

```{r}
#Logisitic model

logitlem_mod<-glm(IsBadBuy~
             VehicleAge+
             VehOdo+
             WarrantyCost+
             Make,,
             data=training,
            na.action=na.exclude,
            family=binomial(link="logit"),
               y=TRUE)

summary(logitlem_mod)
```

With these results in hand we can generate predicted probabilities and see if this model did any better. To get predicted probabilities, we need to specify `type=response` in our prediction call. 

```{r}
training<-training%>%
  mutate(pred_logitlem=predict(logitlem_mod,type="response"))
```

We can convert the predictions to a binary variable by setting a "threshold" of .5. Any prediction above .5 is considered to be a 1, anything below, a 0. 
```{r}


training<-training%>%
    mutate(pred_logitlem_out=ifelse(pred_logitlem>=.3,1,0))

training<-training%>%
    mutate(pred_logitlem_out=as.factor(pred_logitlem_out))

training<-training%>%
    mutate(IsBadBuy=as.factor(IsBadBuy))
```

Now we create a confusion matrix to see how we did. 
```{r}
confusionMatrix(data=as.factor(training$pred_logitlem_out),reference=as.factor(training$IsBadBuy))
```

## 6. Make predictions from the logit model. Make sure these are probabilities. 

See Line 155

## 6. Make predictions from the logit model. Make sure these are probabilities. 

## Applying predictions to the testing dataset.

With our new (not very good) classifier, we can now add predictions to the testing dataset, and see how good this classifier is at predicting out of sample information. 

```{r}
#load("testing.RData")

test<-test%>%
  mutate(pred_logit=predict(logitlem_mod,newdata=.,type="response"))%>%
      mutate(predlem_logit_out=ifelse(predlem_logit>=.5,1,0))

test<-test%>%
    mutate(predlem_logit_out=as.factor(predlem_logit_out))

test<-test%>%
    mutate(IsBadBuy=as.factor(IsBadBuy))


confusionMatrix(data=test$predlem_logit_out,reference=test$IsBadBuy)
```

## 7. Create a confusion matrix from your linear model and your logit model.

See Line 128 and 178
